{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forcateri.model.dartsmodels.dartstcnmodel import DartsTCNModel\n",
    "from forcateri.baltbestapi.baltbestaggregatedapidata import BaltBestAggregatedAPIData\n",
    "import pandas as pd\n",
    "from forcateri.data.dataprovider import DataProvider, SeriesRole\n",
    "from darts.models import TCNModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from forcateri.data.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baltbest = BaltBestAggregatedAPIData(\n",
    "#     name='test', \n",
    "#     url=\"baltbest_url\", \n",
    "#     local_copy=\"/home/user/DFKI/forcateri/_data/showcase_data.csv\",\n",
    "#     target = 'q_hca',\n",
    "#     group_col = 'room_id',\n",
    "#     time_col = 'datetime',\n",
    "#     known = 'temperature_outdoor_avg',\n",
    "#     observed = ['temperature_1_max', 'temperature_2_max','temperature_room_avg'],)\n",
    "baltbest = BaltBestAggregatedAPIData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Get the logger you used in your TimeSeries class\n",
    "logger = logging.getLogger(\"forcateri.data.timeseries\")\n",
    "logger.setLevel(logging.INFO)  # or logging.DEBUG for more verbosity\n",
    "\n",
    "# Create handler if it doesn't exist\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# Optional: prevent propagation to avoid double logs\n",
    "logger.propagate = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#baltbest.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'q_hca': SeriesRole.TARGET, \n",
    "    'temperature_outdoor_avg':SeriesRole.KNOWN, \n",
    "    'temperature_1_max':SeriesRole.OBSERVED, \n",
    "    'temperature_2_max':SeriesRole.OBSERVED,\n",
    "    'temperature_room_avg':SeriesRole.OBSERVED,}\n",
    "#['temperature_1_max', 'temperature_2_max','temperature_room_avg']\n",
    "# roles = {\n",
    "#     'delta': SeriesRole.TARGET, \n",
    "#     'outside_temp':SeriesRole.KNOWN, \n",
    "#     'max_temperature_1':SeriesRole.OBSERVED, \n",
    "#     'max_temperature_1':SeriesRole.OBSERVED,\n",
    "#     'room_temperature':SeriesRole.OBSERVED,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.Timestamp(2021, 1, 3, 4,tz=0)\n",
    "end = pd.Timestamp(2021, 1, 8, 4,tz=0)\n",
    "dataprovider = DataProvider(data_sources=[baltbest], roles=roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataprovider.get_train_set()\n",
    "val = dataprovider.get_val_set()\n",
    "test = dataprovider.get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].target.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# quantiles = [0.1, 0.5, 0.9]\n",
    "# dartstcn = DartsTCNModel( quantiles=quantiles)\n",
    "# dartstcn.fit(train_data = train, val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_forecast_steps = 5\n",
    "#num_monte_carlo_samples = 50 # A sufficient number of samples to approximate the quantiles\n",
    "dartstcn = DartsTCNModel.load( \"/home/user/DFKI/forcateri/_data/dartstcn.pt\")\n",
    "quantiles = [0.1, 0.5, 0.9] # Define the quantiles you want to predict\n",
    "dartstcn.quantiles = quantiles\n",
    "#Here prediction is darts timeseries\n",
    "prediction = dartstcn.predict(\n",
    "    data=val, # Pass the series used for prediction context\n",
    "    predict_likelihood_parameters = True,\n",
    "    n=num_forecast_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "def mprint(s): display(Markdown(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ts = dartstcn.to_time_series(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = prediction_ts[0].data\n",
    "#Need to fix timestamp and offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Offsets (timedeltas)\n",
    "offsets = pd.to_timedelta(['1:00:00', '2:00:00', '3:00:00', '4:00:00', '5:00:00'])\n",
    "\n",
    "# Multiple timestamps per offset\n",
    "time_stamps = pd.to_datetime([\n",
    "    '2020-08-29 03:00:00',\n",
    "    '2020-08-29 04:00:00',\n",
    "    '2020-08-29 05:00:00',\n",
    "])\n",
    "\n",
    "# Cartesian product for MultiIndex rows\n",
    "offset_repeated = np.repeat(offsets.values, len(time_stamps))\n",
    "time_stamp_tiled = np.tile(time_stamps.values, len(offsets))\n",
    "\n",
    "multi_idx = pd.MultiIndex.from_arrays(\n",
    "    [offset_repeated, time_stamp_tiled],\n",
    "    names=['offset', 'time_stamp']\n",
    ")\n",
    "\n",
    "N = len(multi_idx)\n",
    "\n",
    "# Generate base data\n",
    "base = np.random.normal(loc=0, scale=1, size=N)\n",
    "q_01 = base - 1.0\n",
    "q_05 = base\n",
    "q_09 = base + 1.0\n",
    "\n",
    "data = np.vstack([q_01, q_05, q_09]).T  # shape (N, 3)\n",
    "\n",
    "# Define MultiIndex for columns: level 0 = 'feature' name, level 1 = representation\n",
    "col_idx = pd.MultiIndex.from_product(\n",
    "    [['q_hca'], [0.1, 0.5, 0.9]],\n",
    "    names=['feature', 'representation']\n",
    ")\n",
    "\n",
    "df_synthetic = pd.DataFrame(data, index=multi_idx, columns=col_idx)\n",
    "\n",
    "df_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for offset_value, group_df in df_synthetic.groupby(level='offset'):\n",
    "    ax = group_df.droplevel('offset').plot(\n",
    "        marker='o', \n",
    "        title=f'Offset: {offset_value}', \n",
    "        xlabel='time_stamp', \n",
    "        ylabel='Value'\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_plot = df_synthetic.reset_index()\n",
    "n_offsets = len(offsets)\n",
    "\n",
    "# Setup subplots: 2 columns, adjust rows automatically\n",
    "ncols = 2\n",
    "nrows = (n_offsets + 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(14, 4*nrows), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, offset in enumerate(offsets):\n",
    "    ax = axes[i]\n",
    "    df_sub = df_plot[df_plot['offset'] == offset]\n",
    "\n",
    "    # Plotting feature columns: assuming MultiIndex columns like ('feature', 0.1), ('feature', 0.5), etc.\n",
    "    # We'll plot each feature (the second level of columns)\n",
    "    for val in df_synthetic.columns.levels[1]:\n",
    "        sns.lineplot(\n",
    "            x='time_stamp', \n",
    "            y=('feature', val), \n",
    "            data=df_sub, \n",
    "            marker='o', \n",
    "            label=f'feature {val}',\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "    ax.set_title(f'Offset: {offset}')\n",
    "    ax.set_xlabel('Time Stamp')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend()\n",
    "\n",
    "# Remove unused subplots (if any)\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
